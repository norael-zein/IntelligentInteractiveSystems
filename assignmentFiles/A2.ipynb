{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we provide two parts of the dataset: dataset.csv and test_to_submit.csv. While the former contains all the features and labels, the latter only contains features. During this assignment you will train and test a model using the first dataset. Then, using your trained model, you will be asked to classify the samples in test_to_submit.csv and submit the output of your model. We will check, using our internal labels, the performance of your model on this last dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass this Assignment, you are required to perform the following steps:\n",
    "\n",
    "1. Read and Preprocess the dataset in a format that is appropriate for training\n",
    "2. Do a balanced split of the dataset for train/val/test.\n",
    "3. Select an appropriate model for the task. You can choose among the following:\n",
    "    * A model that was presented during Lab 2\n",
    "    * A model that is part of scikit-learnLinks to an external site. that was not presented in Lab 2\n",
    "    * A different model using PyTorchLinks to an external site.\n",
    "4. Do some kind of hyperparameter tuning/model selection using the validation dataset. Some examples are the following:\n",
    "    * Using different kernels with Support Vector Machines (SVM)\n",
    "    * Using different k values when using k-Nearest Neighbours\n",
    "    * Changing the depth and breadth of a Multi-Layer Perceptron (MLP)\n",
    "    * Testing different model e.g. k-NN vs SVM vs MLP\n",
    "5. Analyse and report the performance of your selected model with your selected hyperparameter(s) on your test set.\n",
    "6. Classify the samples of test_to_submit.csv\n",
    "7. Submit everything on Studium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you will be asked to submit:\n",
    "\n",
    "A very brief report (in pdf) with bullet points answering the following questions (also see example answers):\n",
    "\n",
    "* Name: Your name\n",
    "* Train/val/test split percentage: 70/20/10\n",
    "* Selected model(s): k-NN\n",
    "* Hyperparameter tuning or model selection: Hyperparameter tuning\n",
    "* If Hyperparameter tuning, parameter that was tuned and range of values: k as in the number of clusters, values: 1, 3, 5, 15\n",
    "* Best model/hyperparameter: k=5\n",
    "* Performance of best model on your test set (accuracy): 42%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside this, you are also asked to submit a file containing the classifications of your model of the samples in test_to_submit.csv. The file must be named outputs (with no extension i.e. outputs.txt will not be accepted) and have exactly one word per line. The word corresponds to the emotion label given by your model i.e. the i-th line of your file indicates the emotion label given by your model to the i-th sample in test_to_submit.csv.\n",
    "\n",
    "Finally, you need to submit your code, in a single script or notebook. Do not zip your files.\n",
    "\n",
    "Failure to comply to this given name/structure will result in automatic failure of the assignment. In such case, you can still resubmit your assignment until the end of the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import optuna\n",
    "\n",
    "##\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition and inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "eval_set = pd.read_csv(\"test_to_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>AU05</th>\n",
       "      <th>AU06</th>\n",
       "      <th>AU07</th>\n",
       "      <th>AU09</th>\n",
       "      <th>AU10</th>\n",
       "      <th>AU11</th>\n",
       "      <th>...</th>\n",
       "      <th>AU14</th>\n",
       "      <th>AU15</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.450774</td>\n",
       "      <td>0.289915</td>\n",
       "      <td>0.409713</td>\n",
       "      <td>0.518726</td>\n",
       "      <td>0.086218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187309</td>\n",
       "      <td>0.354838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320690</td>\n",
       "      <td>0.411641</td>\n",
       "      <td>0.431646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277122</td>\n",
       "      <td>0.335435</td>\n",
       "      <td>0.262999</td>\n",
       "      <td>0.189863</td>\n",
       "      <td>0.051967</td>\n",
       "      <td>0.051370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>0.500450</td>\n",
       "      <td>0.314694</td>\n",
       "      <td>0.625174</td>\n",
       "      <td>0.335747</td>\n",
       "      <td>0.262984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504238</td>\n",
       "      <td>0.383201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544159</td>\n",
       "      <td>0.440429</td>\n",
       "      <td>0.495913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514737</td>\n",
       "      <td>0.420401</td>\n",
       "      <td>0.052358</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.500994</td>\n",
       "      <td>0.155117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad</td>\n",
       "      <td>0.273191</td>\n",
       "      <td>0.191327</td>\n",
       "      <td>0.140938</td>\n",
       "      <td>0.358091</td>\n",
       "      <td>0.246593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312881</td>\n",
       "      <td>0.188845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284598</td>\n",
       "      <td>0.761539</td>\n",
       "      <td>0.491468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134049</td>\n",
       "      <td>0.670237</td>\n",
       "      <td>0.024796</td>\n",
       "      <td>0.109462</td>\n",
       "      <td>0.325429</td>\n",
       "      <td>0.191367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.464508</td>\n",
       "      <td>0.301702</td>\n",
       "      <td>0.500370</td>\n",
       "      <td>0.296161</td>\n",
       "      <td>0.189114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521304</td>\n",
       "      <td>0.039475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491734</td>\n",
       "      <td>0.163430</td>\n",
       "      <td>0.552469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419418</td>\n",
       "      <td>0.306920</td>\n",
       "      <td>0.224105</td>\n",
       "      <td>0.072518</td>\n",
       "      <td>0.652248</td>\n",
       "      <td>0.505568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.274483</td>\n",
       "      <td>0.232007</td>\n",
       "      <td>0.601821</td>\n",
       "      <td>0.281365</td>\n",
       "      <td>0.900241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.784789</td>\n",
       "      <td>0.198816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703261</td>\n",
       "      <td>0.549239</td>\n",
       "      <td>0.425561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203916</td>\n",
       "      <td>0.561599</td>\n",
       "      <td>0.966706</td>\n",
       "      <td>0.108249</td>\n",
       "      <td>0.464104</td>\n",
       "      <td>0.786888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion      AU01      AU02      AU04      AU05      AU06  AU07      AU09  \\\n",
       "0  neutral  0.450774  0.289915  0.409713  0.518726  0.086218   0.0  0.187309   \n",
       "1  disgust  0.500450  0.314694  0.625174  0.335747  0.262984   0.0  0.504238   \n",
       "2      sad  0.273191  0.191327  0.140938  0.358091  0.246593   0.0  0.312881   \n",
       "3  neutral  0.464508  0.301702  0.500370  0.296161  0.189114   0.0  0.521304   \n",
       "4    happy  0.274483  0.232007  0.601821  0.281365  0.900241   1.0  0.784789   \n",
       "\n",
       "       AU10  AU11  ...      AU14      AU15      AU17  AU20      AU23  \\\n",
       "0  0.354838   0.0  ...  0.320690  0.411641  0.431646   0.0  0.277122   \n",
       "1  0.383201   0.0  ...  0.544159  0.440429  0.495913   0.0  0.514737   \n",
       "2  0.188845   1.0  ...  0.284598  0.761539  0.491468   0.0  0.134049   \n",
       "3  0.039475   0.0  ...  0.491734  0.163430  0.552469   0.0  0.419418   \n",
       "4  0.198816   0.0  ...  0.703261  0.549239  0.425561   0.0  0.203916   \n",
       "\n",
       "       AU24      AU25      AU26      AU28      AU43  \n",
       "0  0.335435  0.262999  0.189863  0.051967  0.051370  \n",
       "1  0.420401  0.052358  0.143576  0.500994  0.155117  \n",
       "2  0.670237  0.024796  0.109462  0.325429  0.191367  \n",
       "3  0.306920  0.224105  0.072518  0.652248  0.505568  \n",
       "4  0.561599  0.966706  0.108249  0.464104  0.786888  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161, 21)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>AU05</th>\n",
       "      <th>AU06</th>\n",
       "      <th>AU07</th>\n",
       "      <th>AU09</th>\n",
       "      <th>AU10</th>\n",
       "      <th>AU11</th>\n",
       "      <th>AU12</th>\n",
       "      <th>AU14</th>\n",
       "      <th>AU15</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.405237</td>\n",
       "      <td>0.479319</td>\n",
       "      <td>0.265762</td>\n",
       "      <td>0.274633</td>\n",
       "      <td>0.580491</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.548356</td>\n",
       "      <td>0.023748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>0.660568</td>\n",
       "      <td>0.330212</td>\n",
       "      <td>0.474759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560595</td>\n",
       "      <td>0.339413</td>\n",
       "      <td>0.712796</td>\n",
       "      <td>0.041511</td>\n",
       "      <td>0.144623</td>\n",
       "      <td>0.377551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.409071</td>\n",
       "      <td>0.388340</td>\n",
       "      <td>0.281202</td>\n",
       "      <td>0.318302</td>\n",
       "      <td>0.275725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438240</td>\n",
       "      <td>0.737880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.280625</td>\n",
       "      <td>0.297689</td>\n",
       "      <td>0.618692</td>\n",
       "      <td>0.373158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362552</td>\n",
       "      <td>0.071052</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.706376</td>\n",
       "      <td>0.097503</td>\n",
       "      <td>0.371425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.354260</td>\n",
       "      <td>0.398113</td>\n",
       "      <td>0.184397</td>\n",
       "      <td>0.412723</td>\n",
       "      <td>0.119522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170188</td>\n",
       "      <td>0.195084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100838</td>\n",
       "      <td>0.534023</td>\n",
       "      <td>0.552444</td>\n",
       "      <td>0.511086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424541</td>\n",
       "      <td>0.537576</td>\n",
       "      <td>0.805593</td>\n",
       "      <td>0.156587</td>\n",
       "      <td>0.064540</td>\n",
       "      <td>0.101149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157341</td>\n",
       "      <td>0.140977</td>\n",
       "      <td>0.329866</td>\n",
       "      <td>0.341054</td>\n",
       "      <td>0.150011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263753</td>\n",
       "      <td>0.078781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114097</td>\n",
       "      <td>0.323225</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>0.487765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.273257</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>0.080303</td>\n",
       "      <td>0.563623</td>\n",
       "      <td>0.283418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.273054</td>\n",
       "      <td>0.354161</td>\n",
       "      <td>0.177498</td>\n",
       "      <td>0.337357</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309611</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134032</td>\n",
       "      <td>0.228593</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.363071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.351714</td>\n",
       "      <td>0.436756</td>\n",
       "      <td>0.979297</td>\n",
       "      <td>0.319223</td>\n",
       "      <td>0.172709</td>\n",
       "      <td>0.204042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AU01      AU02      AU04      AU05      AU06  AU07      AU09      AU10  \\\n",
       "0  0.405237  0.479319  0.265762  0.274633  0.580491   1.0  0.548356  0.023748   \n",
       "1  0.409071  0.388340  0.281202  0.318302  0.275725   0.0  0.438240  0.737880   \n",
       "2  0.354260  0.398113  0.184397  0.412723  0.119522   0.0  0.170188  0.195084   \n",
       "3  0.157341  0.140977  0.329866  0.341054  0.150011   0.0  0.263753  0.078781   \n",
       "4  0.273054  0.354161  0.177498  0.337357  0.155787   0.0  0.309611  0.002358   \n",
       "\n",
       "   AU11      AU12      AU14      AU15      AU17  AU20      AU23      AU24  \\\n",
       "0   0.0  0.860109  0.660568  0.330212  0.474759   0.0  0.560595  0.339413   \n",
       "1   1.0  0.280625  0.297689  0.618692  0.373158   1.0  0.362552  0.071052   \n",
       "2   1.0  0.100838  0.534023  0.552444  0.511086   0.0  0.424541  0.537576   \n",
       "3   0.0  0.114097  0.323225  0.151836  0.487765   0.0  0.253994  0.273257   \n",
       "4   1.0  0.134032  0.228593  0.482891  0.363071   1.0  0.351714  0.436756   \n",
       "\n",
       "       AU25      AU26      AU28      AU43  \n",
       "0  0.712796  0.041511  0.144623  0.377551  \n",
       "1  0.999756  0.706376  0.097503  0.371425  \n",
       "2  0.805593  0.156587  0.064540  0.101149  \n",
       "3  0.035888  0.080303  0.563623  0.283418  \n",
       "4  0.979297  0.319223  0.172709  0.204042  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161, 21)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data\n",
    "Train/val/test split percentage: 70/20/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[\"emotion\"]\n",
    "inputs = data.drop(labels=\"emotion\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'angry': 0, \n",
    "    'disgust': 1, \n",
    "    'fear': 2, \n",
    "    'happy': 3, \n",
    "    'neutral': 4, \n",
    "    'sad': 5, \n",
    "    'surprise': 6\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4\n",
       "1       1\n",
       "2       5\n",
       "3       4\n",
       "4       3\n",
       "       ..\n",
       "1156    5\n",
       "1157    5\n",
       "1158    4\n",
       "1159    4\n",
       "1160    6\n",
       "Name: emotion, Length: 1161, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relabel data to integers so predictions are in numeric format\n",
    "y = labels.map(label_map)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1161])\n",
      "torch.Size([1161, 20])\n"
     ]
    }
   ],
   "source": [
    "#convert to tensors for compatibility with pytorch\n",
    "features = torch.tensor(inputs.values, dtype=torch.float32)  \n",
    "y = torch.tensor(y.values, dtype=torch.long)\n",
    "\n",
    "print(y.shape)\n",
    "print(features.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, X_test, y_labels, y_test = train_test_split(\n",
    "    features,\n",
    "    y,\n",
    "    test_size=.1,\n",
    "    random_state = 42, #shuffled in same way\n",
    "    stratify = y#make sure label distribution is same over train and test\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_data,\n",
    "    y_labels,\n",
    "    test_size=.2222222222,  #\n",
    "    random_state = 42, #shuffled in same way\n",
    "    stratify = y_labels#make sure label distribution is same over train and test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10077519379844961"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)/len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19982773471145565"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)/len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6993970714900948"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)/len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "https://optuna.org/ for tutorial on hyperparameter tuning\n",
    "https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py for example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just a simple sequential model for classification delete when optuna implemented\n",
    "#note for future. don't be lazy and just extend nn.Module next time.\n",
    "def create_model(trial = None, params = None):\n",
    "\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3) if trial else params['n_layers']\n",
    "    layers = []\n",
    "\n",
    "    in_features = 20\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f'n_units_l{i}', 32, 128,step=32) if trial else params[f'n_units_l{i}']\n",
    "        layers.append(torch.nn.Linear(in_features, out_features))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        perc = trial.suggest_float(\"dropout_l{}\".format(i), 0, 0.5, step=.1) if trial else params[f'dropout_l{i}']\n",
    "        layers.append(torch.nn.Dropout(perc))\n",
    "        in_features = out_features\n",
    "    \n",
    "    layers.append(torch.nn.Linear(in_features, 7))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global best_acc, best_model_state\n",
    "    #initialize model. device defined in header, eh just use cpu\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    learning_rate_init = trial.suggest_float(\n",
    "        \"learning_rate_init\", 1e-5, 1e-3, log=True\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate_init)\n",
    "    criterion = nn.CrossEntropyLoss()   #multiclass classification\n",
    "    epochs = 10\n",
    "    \n",
    "    #Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train() #enables dropout\n",
    "        #loop over data\n",
    "        for (data, target) in zip(X_train,y_train):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        #validation\n",
    "        model.eval()    #eval() for disabling dropout\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for (data,target) in zip(X_val,y_val):\n",
    "                output = model(data)\n",
    "                pred = output.argmax()\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                \n",
    "        accuracy = correct/len(X_val)   #should minimize val loss instead of maximize val acc\n",
    "        \n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    #save model if best?\n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_model_state = model.state_dict()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-22 15:21:19,001] A new study created in memory with name: no-name-7a1130ff-fe57-4675-95cb-a0bea67b6724\n",
      "[I 2024-11-22 15:25:23,394] Trial 0 finished with value: 0.5818965517241379 and parameters: {'n_layers': 3, 'n_units_l0': 64, 'dropout_l0': 0.30000000000000004, 'n_units_l1': 128, 'dropout_l1': 0.5, 'n_units_l2': 32, 'dropout_l2': 0.5, 'learning_rate_init': 0.0001892126622843035}. Best is trial 0 with value: 0.5818965517241379.\n",
      "[I 2024-11-22 15:26:49,062] Trial 1 finished with value: 0.5948275862068966 and parameters: {'n_layers': 2, 'n_units_l0': 128, 'dropout_l0': 0.2, 'n_units_l1': 128, 'dropout_l1': 0.2, 'learning_rate_init': 0.0008210126044095739}. Best is trial 1 with value: 0.5948275862068966.\n",
      "[I 2024-11-22 15:28:13,190] Trial 2 finished with value: 0.6120689655172413 and parameters: {'n_layers': 3, 'n_units_l0': 96, 'dropout_l0': 0.30000000000000004, 'n_units_l1': 128, 'dropout_l1': 0.5, 'n_units_l2': 96, 'dropout_l2': 0.4, 'learning_rate_init': 0.00017076242482472065}. Best is trial 2 with value: 0.6120689655172413.\n",
      "[I 2024-11-22 15:29:09,316] Trial 3 finished with value: 0.5818965517241379 and parameters: {'n_layers': 3, 'n_units_l0': 64, 'dropout_l0': 0.30000000000000004, 'n_units_l1': 64, 'dropout_l1': 0.0, 'n_units_l2': 64, 'dropout_l2': 0.30000000000000004, 'learning_rate_init': 0.00020770289271422116}. Best is trial 2 with value: 0.6120689655172413.\n",
      "[I 2024-11-22 15:30:26,889] Trial 4 finished with value: 0.5732758620689655 and parameters: {'n_layers': 3, 'n_units_l0': 64, 'dropout_l0': 0.5, 'n_units_l1': 64, 'dropout_l1': 0.4, 'n_units_l2': 128, 'dropout_l2': 0.5, 'learning_rate_init': 0.00016700447702191478}. Best is trial 2 with value: 0.6120689655172413.\n",
      "[I 2024-11-22 15:30:31,997] Trial 5 pruned. \n",
      "[I 2024-11-22 15:30:37,605] Trial 6 pruned. \n",
      "[I 2024-11-22 15:31:28,448] Trial 7 pruned. \n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_model_state = None\n",
    "#create study and start tuning!\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20, timeout=600)\n",
    "\n",
    "best = study.best_trial\n",
    "torch.save(best_model_state, \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Params: \n",
      "    n_layers: 3\n",
      "    n_units_l0: 96\n",
      "    dropout_l0: 0.30000000000000004\n",
      "    n_units_l1: 128\n",
      "    dropout_l1: 0.5\n",
      "    n_units_l2: 96\n",
      "    dropout_l2: 0.4\n",
      "    learning_rate_init: 0.00017076242482472065\n"
     ]
    }
   ],
   "source": [
    "#best trial parameters\n",
    "print(\"  Params: \")\n",
    "for key, value in best.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load best model params, saved weights, and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_880/3376511732.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(\"best_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "#params\n",
    "best_model = create_model(params = best.params)\n",
    "\n",
    "#load weights\n",
    "best_model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "#eval\n",
    "best_model.eval()    #eval() for disabling dropout\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for (data,target) in zip(X_test,y_test):\n",
    "        output = best_model(data)\n",
    "        pred = output.argmax()\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                \n",
    "accuracy = correct/len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6239316239316239"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#didn't want to implement early stopping and keep training, so here's accuracy after tuning\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_submit = pd.read_csv(\"test_to_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>AU05</th>\n",
       "      <th>AU06</th>\n",
       "      <th>AU07</th>\n",
       "      <th>AU09</th>\n",
       "      <th>AU10</th>\n",
       "      <th>AU11</th>\n",
       "      <th>AU12</th>\n",
       "      <th>AU14</th>\n",
       "      <th>AU15</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.405237</td>\n",
       "      <td>0.479319</td>\n",
       "      <td>0.265762</td>\n",
       "      <td>0.274633</td>\n",
       "      <td>0.580491</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.548356</td>\n",
       "      <td>0.023748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>0.660568</td>\n",
       "      <td>0.330212</td>\n",
       "      <td>0.474759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560595</td>\n",
       "      <td>0.339413</td>\n",
       "      <td>0.712796</td>\n",
       "      <td>0.041511</td>\n",
       "      <td>0.144623</td>\n",
       "      <td>0.377551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.409071</td>\n",
       "      <td>0.388340</td>\n",
       "      <td>0.281202</td>\n",
       "      <td>0.318302</td>\n",
       "      <td>0.275725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438240</td>\n",
       "      <td>0.737880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.280625</td>\n",
       "      <td>0.297689</td>\n",
       "      <td>0.618692</td>\n",
       "      <td>0.373158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362552</td>\n",
       "      <td>0.071052</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.706376</td>\n",
       "      <td>0.097503</td>\n",
       "      <td>0.371425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.354260</td>\n",
       "      <td>0.398113</td>\n",
       "      <td>0.184397</td>\n",
       "      <td>0.412723</td>\n",
       "      <td>0.119522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170188</td>\n",
       "      <td>0.195084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100838</td>\n",
       "      <td>0.534023</td>\n",
       "      <td>0.552444</td>\n",
       "      <td>0.511086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424541</td>\n",
       "      <td>0.537576</td>\n",
       "      <td>0.805593</td>\n",
       "      <td>0.156587</td>\n",
       "      <td>0.064540</td>\n",
       "      <td>0.101149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157341</td>\n",
       "      <td>0.140977</td>\n",
       "      <td>0.329866</td>\n",
       "      <td>0.341054</td>\n",
       "      <td>0.150011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263753</td>\n",
       "      <td>0.078781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114097</td>\n",
       "      <td>0.323225</td>\n",
       "      <td>0.151836</td>\n",
       "      <td>0.487765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.273257</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>0.080303</td>\n",
       "      <td>0.563623</td>\n",
       "      <td>0.283418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.273054</td>\n",
       "      <td>0.354161</td>\n",
       "      <td>0.177498</td>\n",
       "      <td>0.337357</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309611</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134032</td>\n",
       "      <td>0.228593</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.363071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.351714</td>\n",
       "      <td>0.436756</td>\n",
       "      <td>0.979297</td>\n",
       "      <td>0.319223</td>\n",
       "      <td>0.172709</td>\n",
       "      <td>0.204042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AU01      AU02      AU04      AU05      AU06  AU07      AU09      AU10  \\\n",
       "0  0.405237  0.479319  0.265762  0.274633  0.580491   1.0  0.548356  0.023748   \n",
       "1  0.409071  0.388340  0.281202  0.318302  0.275725   0.0  0.438240  0.737880   \n",
       "2  0.354260  0.398113  0.184397  0.412723  0.119522   0.0  0.170188  0.195084   \n",
       "3  0.157341  0.140977  0.329866  0.341054  0.150011   0.0  0.263753  0.078781   \n",
       "4  0.273054  0.354161  0.177498  0.337357  0.155787   0.0  0.309611  0.002358   \n",
       "\n",
       "   AU11      AU12      AU14      AU15      AU17  AU20      AU23      AU24  \\\n",
       "0   0.0  0.860109  0.660568  0.330212  0.474759   0.0  0.560595  0.339413   \n",
       "1   1.0  0.280625  0.297689  0.618692  0.373158   1.0  0.362552  0.071052   \n",
       "2   1.0  0.100838  0.534023  0.552444  0.511086   0.0  0.424541  0.537576   \n",
       "3   0.0  0.114097  0.323225  0.151836  0.487765   0.0  0.253994  0.273257   \n",
       "4   1.0  0.134032  0.228593  0.482891  0.363071   1.0  0.351714  0.436756   \n",
       "\n",
       "       AU25      AU26      AU28      AU43  \n",
       "0  0.712796  0.041511  0.144623  0.377551  \n",
       "1  0.999756  0.706376  0.097503  0.371425  \n",
       "2  0.805593  0.156587  0.064540  0.101149  \n",
       "3  0.035888  0.080303  0.563623  0.283418  \n",
       "4  0.979297  0.319223  0.172709  0.204042  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_to_submit.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([233, 20])\n"
     ]
    }
   ],
   "source": [
    "#convert to tensors for compatibility with pytorch\n",
    "features = torch.tensor(test_to_submit.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = best_model(features).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([233])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'angry',\n",
       " 1: 'disgust',\n",
       " 2: 'fear',\n",
       " 3: 'happy',\n",
       " 4: 'neutral',\n",
       " 5: 'sad',\n",
       " 6: 'surprise'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_label_map = dict(zip(label_map.values(), label_map.keys()))\n",
    "reverse_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.Series(output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    6\n",
       "2    4\n",
       "3    4\n",
       "4    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.map(reverse_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       happy\n",
       "1    surprise\n",
       "2     neutral\n",
       "3     neutral\n",
       "4    surprise\n",
       "dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"outputs\",header=False,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iis24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
